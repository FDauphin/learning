{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing torchvision is incompatible with sklearn in this environment. Load data from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_IMG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = x_train.shape[-1]\n",
    "num_classes = np.unique(y_train).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_train = x_train.shape[0]\n",
    "size_test = x_test.shape[0]\n",
    "scale = x_train.max()\n",
    "x_train_scale = ((x_train / scale) - 0.5) / 0.5\n",
    "x_test_scale = ((x_test / scale) - 0.5) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, sharex=True, sharey=True)\n",
    "for i in range (2):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        mask = y_train == ind\n",
    "        axs[i,j].imshow(np.mean(x_train_scale[mask], axis=0))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, sharex=True, sharey=True)\n",
    "for i in range (2):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        mask = y_test == ind\n",
    "        axs[i,j].imshow(np.mean(x_test_scale[mask], axis=0))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load models (discriminator and generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch models loaded onto cpus is incompatible with scikit learn in this environment. Load models onto gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = 32\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(features=FEATURES, channels_img=CHANNELS_IMG)\n",
    "disc.load_state_dict(torch.load(f'dcgan_disc_2024-04-19_1341.pt'))\n",
    "disc.to(device)\n",
    "disc.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(channels_noise=NOISE_DIM, features=FEATURES, channels_img=CHANNELS_IMG)\n",
    "gen.load_state_dict(torch.load(f'dcgan_gen_2024-04-19_1341.pt'))\n",
    "gen.to(device)\n",
    "gen.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.read_csv('dcgan_loss_2024-04-19_1341.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=[10,5])\n",
    "axs[0].plot(loss['Loss Disc Real'], label='loss disc real')\n",
    "axs[0].plot(loss['Loss Disc Fake'], label='loss disc fake')\n",
    "axs[0].plot(loss['Loss Gen'], label='loss gen')\n",
    "axs[0].legend()\n",
    "axs[1].plot(loss['Mean Disc Real'], label='mean disc real')\n",
    "axs[1].plot(loss['Mean Disc Fake'], label='mean disc fake')\n",
    "axs[1].plot(loss['Mean Disc Fake (Gen Training)'], label='mean disc fake (gen training)')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = torch.randn(size_test, NOISE_DIM, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen_torch = gen(latent)\n",
    "x_gen = x_gen_torch.cpu().detach().numpy().reshape(size_test, IMAGE_SIZE, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fig, axs = plt.subplots(n, n, figsize=[5,5], sharex=True, sharey=True)\n",
    "for i in range (n):\n",
    "    for j in range (n):\n",
    "        ind = i*n+j\n",
    "        axs[i, j].imshow(x_gen[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_sample = disc(x_gen_torch).view(-1).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(disc_sample, bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train PCA-RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9, whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pca.fit_transform(x_train_scale.reshape(size_train, IMAGE_SIZE**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(pca_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = pca.transform(x_test_scale.reshape(size_test, IMAGE_SIZE**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, normalize='true').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Predict generated images with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_gen = pca.transform(x_gen.reshape(size_test, IMAGE_SIZE**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gen = rf.predict(pca_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_train[:, 0], pca_train[:, 1], s=1, alpha=0.1, label='train')\n",
    "plt.scatter(pca_test[:, 0], pca_test[:, 1], s=1, alpha=0.1, label='test')\n",
    "plt.scatter(pca_gen[:, 0], pca_gen[:, 1], s=1, alpha=0.1, label='gen')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_train[:, 0], pca_train[:, 1], s=1, alpha=0.1, label='train', color='k')\n",
    "for i in range (num_classes):\n",
    "    mask = y_gen == i\n",
    "    plt.scatter(pca_gen[:, 0][mask], pca_gen[:, 1][mask], s=1, alpha=1, label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, sharex=True, sharey=True)\n",
    "for i in range (2):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        mask = y_gen == ind\n",
    "        axs[i,j].imshow(np.mean(x_gen[mask], axis=0))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = latent.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ind0, rand_ind1 = np.random.randint(0, size_test, 2)\n",
    "steps = 20\n",
    "interp = np.linspace(latent[rand_ind0], latent[rand_ind1], steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_interp = gen(torch.Tensor(interp).to(device)).cpu().detach().numpy().reshape(steps,IMAGE_SIZE,IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,5, sharex=True, sharey=True)\n",
    "for i in range (4):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        axs[i,j].imshow(gen_interp[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## \"Eigen\" vectors in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 10\n",
    "id_matrix = torch.eye(NOISE_DIM).view(NOISE_DIM, NOISE_DIM, 1, 1).to(device) * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_id = gen(id_matrix).cpu().detach().numpy().reshape(NOISE_DIM, IMAGE_SIZE, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10,10,figsize=[10,10], sharex=True, sharey=True)\n",
    "for i in range (10):\n",
    "    for j in range (10):\n",
    "        ind = i*10+j\n",
    "        axs[i,j].imshow(gen_id[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_manifold = 11\n",
    "x_min, x_max = -11, 11\n",
    "y_min, y_max = -11, 11\n",
    "gen_manifold_ind = []\n",
    "gen_manifold = []\n",
    "for i in np.linspace(y_max,y_min,n_manifold):\n",
    "    for j in np.linspace(x_min,x_max,n_manifold):\n",
    "        gen_manifold_ind.append([j, i])\n",
    "        latent_m = torch.zeros(1, NOISE_DIM, 1, 1).to(device)\n",
    "        latent_m[0, 0, 0, 0] = j\n",
    "        latent_m[0, 1, 0, 0] = i\n",
    "        gen_m = gen(latent_m).cpu().detach().numpy().reshape(IMAGE_SIZE, IMAGE_SIZE)\n",
    "        gen_manifold.append(gen_m)\n",
    "gen_manifold_ind = np.array(gen_manifold_ind)\n",
    "gen_manifold = np.array(gen_manifold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifold = np.zeros((n_manifold*IMAGE_SIZE, n_manifold*IMAGE_SIZE))\n",
    "for i in range (n_manifold):\n",
    "    for j in range (n_manifold):\n",
    "        ymin = i*IMAGE_SIZE\n",
    "        ymax = (i+1)*IMAGE_SIZE\n",
    "        xmin = j*IMAGE_SIZE\n",
    "        xmax = (j+1)*IMAGE_SIZE\n",
    "        manifold[ymin:ymax, xmin:xmax] = gen_manifold[i*n_manifold+j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(manifold, extent=[x_min,x_max,y_min,y_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Latent space vector addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ind0, rand_ind1 = np.random.randint(0, size_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_add = torch.Tensor(latent[rand_ind0] + latent[rand_ind1]).reshape(1, NOISE_DIM, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_add = gen(latent_add).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(x_gen[rand_ind0])\n",
    "axs[1].imshow(x_gen[rand_ind1])\n",
    "axs[2].imshow(gen_add[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Find mean/std latent vectors for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_mean = []\n",
    "latent_std = []\n",
    "for i in range (num_classes):\n",
    "    latent_mean_i = np.mean(latent[y_gen==i], axis=0)\n",
    "    latent_std_i = np.std(latent[y_gen==i], axis=0)\n",
    "    latent_mean.append(latent_mean_i)\n",
    "    latent_std.append(latent_std_i)\n",
    "latent_mean = np.array(latent_mean)\n",
    "latent_std = np.array(latent_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_mean.shape, latent_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,sharex=True)\n",
    "axs[0].set_title('mean')\n",
    "axs[0].imshow(latent_mean.reshape(num_classes, NOISE_DIM))\n",
    "axs[1].set_title('std')\n",
    "axs[1].imshow(latent_std.reshape(num_classes, NOISE_DIM))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mean = gen(torch.Tensor(latent_mean).to(device)).cpu().detach().numpy().reshape(num_classes,IMAGE_SIZE,IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, sharex=True, sharey=True)\n",
    "for i in range (2):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        axs[i,j].imshow(gen_mean[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sample latent space around normal distribution for a class (naive conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = 9\n",
    "n_samples = 100\n",
    "latent_class = []\n",
    "for i in range (NOISE_DIM):\n",
    "    noise_dimension = np.random.normal(latent_mean[digit, i, 0, 0], latent_std[digit, i, 0, 0], n_samples)\n",
    "    latent_class.append(noise_dimension)\n",
    "latent_class = np.array(latent_class).T.reshape(n_samples, NOISE_DIM, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_class = gen(torch.Tensor(latent_class).to(device)).cpu().detach().numpy().reshape(n_samples,IMAGE_SIZE,IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10,10,figsize=[10,10], sharex=True, sharey=True)\n",
    "for i in range (10):\n",
    "    for j in range (10):\n",
    "        ind = i*10+j\n",
    "        axs[i,j].imshow(gen_class[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
