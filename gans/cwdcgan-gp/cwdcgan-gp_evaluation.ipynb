{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Critic, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing torchvision is incompatible with sklearn in this environment. Load data from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_IMG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = x_train.shape[-1]\n",
    "NUM_CLASSES = np.unique(y_train).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_train = x_train.shape[0]\n",
    "size_test = x_test.shape[0]\n",
    "scale = x_train.max()\n",
    "x_train_scale = ((x_train / scale) - 0.5) / 0.5\n",
    "x_test_scale = ((x_test / scale) - 0.5) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, sharex=True, sharey=True)\n",
    "for i in range (2):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        mask = y_train == ind\n",
    "        axs[i,j].imshow(np.mean(x_train_scale[mask], axis=0))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5, sharex=True, sharey=True)\n",
    "for i in range (2):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        mask = y_test == ind\n",
    "        axs[i,j].imshow(np.mean(x_test_scale[mask], axis=0))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load models (critic and generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch models loaded onto cpus is incompatible with scikit learn in this environment. Load models onto gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = 32\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic(features=FEATURES, channels_img=CHANNELS_IMG, img_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "critic.load_state_dict(torch.load(f'cwdcgan-gp_critic_2024-04-23_1738.pt'))\n",
    "critic.to(device)\n",
    "critic.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(channels_noise=NOISE_DIM, features=FEATURES, channels_img=CHANNELS_IMG, num_classes=NUM_CLASSES)\n",
    "gen.load_state_dict(torch.load(f'cwdcgan-gp_gen_2024-04-23_1738.pt'))\n",
    "gen.to(device)\n",
    "gen.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.read_csv('cwdcgan-gp_loss_2024-04-23_1738.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_critic = loss['Loss Critic Fake'] - loss['Loss Critic Real'] + loss['Loss Critic Gradient Penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=[10,5])\n",
    "axs[0].plot(loss_critic, label='loss critic', color='k')\n",
    "axs[0].plot(loss['Loss Gen'], label='loss gen', color='C3')\n",
    "axs[0].legend()\n",
    "axs[1].plot(loss['Loss Critic Real'], label='loss critic real')\n",
    "axs[1].plot(loss['Loss Critic Fake'], label='loss critic fake')\n",
    "axs[1].plot(loss['Loss Critic Gradient Penalty'], label='loss critic gp')\n",
    "axs[1].plot(loss['Loss Gen'], label='loss gen')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 16\n",
    "latent = torch.randn(num_samples, NOISE_DIM, 1, 1).to(device)\n",
    "digit = 0\n",
    "label = torch.ones(num_samples).type(torch.LongTensor).to(device) * digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen_torch = gen(latent, label)\n",
    "x_gen = x_gen_torch.cpu().detach().numpy().reshape(num_samples, IMAGE_SIZE, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fig, axs = plt.subplots(n, n, figsize=[5,5], sharex=True, sharey=True)\n",
    "for i in range (n):\n",
    "    for j in range (n):\n",
    "        ind = i*n+j\n",
    "        axs[i, j].imshow(x_gen[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit1, digit2 = 3, 6\n",
    "label1 = torch.ones(1).type(torch.LongTensor).to(device) * digit1\n",
    "label2 = torch.ones(1).type(torch.LongTensor).to(device) * digit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed1 = gen.embed(label1).cpu().detach().numpy().reshape(NOISE_DIM, 1, 1)\n",
    "embed2 = gen.embed(label2).cpu().detach().numpy().reshape(NOISE_DIM, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 20\n",
    "embed_interp = torch.Tensor(np.linspace(embed1, embed2, steps)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent1 = np.random.standard_normal((NOISE_DIM, 1, 1))\n",
    "latent2 = np.random.standard_normal((NOISE_DIM, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_interp = torch.Tensor(np.linspace(latent1, latent2, steps)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_interp = torch.cat([latent_interp, embed_interp], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_interp = gen.gen(x_interp).cpu().detach().numpy().reshape(steps,IMAGE_SIZE,IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,5, sharex=True, sharey=True)\n",
    "for i in range (4):\n",
    "    for j in range (5):\n",
    "        ind = i*5+j\n",
    "        axs[i,j].imshow(gen_interp[ind])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generator filter weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_block1_conv_filters = gen.block4[0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = gen_block1_conv_filters.min()\n",
    "vmax = gen_block1_conv_filters.max()\n",
    "fig, axs = plt.subplots(4, 8, sharex=True, sharey=True)\n",
    "for i in range (4):\n",
    "    for j in range (8):\n",
    "        ind = i*8+j\n",
    "        axs[i, j].set_title(f'{ind}: {i}, {j}')\n",
    "        axs[i, j].imshow(gen_block1_conv_filters[ind, 0], vmin=vmin, vmax=vmax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
